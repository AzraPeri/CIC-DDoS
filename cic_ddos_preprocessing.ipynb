{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4059918,"sourceType":"datasetVersion","datasetId":2398189}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# AdÄ±m 1: Kurulum, veri yÃ¼kleme, temizlik (Kaggle iÃ§in)\nimport os, glob, warnings, numpy as np, pandas as pd\nwarnings.filterwarnings(\"ignore\")\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\n\nDATA_DIR = \"/kaggle/input/cicddos2019\"\nTARGET   = \"__label__\"\n\ndef infer_label(fname):  # Syn-training.parquet -> Syn\n    return os.path.basename(fname).split(\"-\")[0]\ndef infer_split(fname):  # train/test bilgisi\n    b = os.path.basename(fname).lower()\n    return \"train\" if \"train\" in b else (\"test\" if \"test\" in b else \"unknown\")\n\n# 1.1 Parquetleri birleÅŸtir\nframes=[]\nfor f in sorted(glob.glob(os.path.join(DATA_DIR,\"*.parquet\"))):\n    df = pd.read_parquet(f)\n    df[\"__split__\"] = infer_split(f)\n    df[TARGET]      = infer_label(f)\n    frames.append(df)\nraw = pd.concat(frames, ignore_index=True)\n\n# 1.2 Temizlik: inf->NaN, kategorik/sabit kolonlarÄ± at\nraw = raw.replace([np.inf,-np.inf], np.nan)\nMETA = [TARGET,\"__split__\"]\nfeatures = [c for c in raw.columns if c not in META]\nnum_cols = [c for c in features if pd.api.types.is_numeric_dtype(raw[c])]\ndf = raw.drop(columns=[c for c in features if c not in num_cols]).copy()\nconstant = df[num_cols].nunique(dropna=False)\nconst_cols = constant[constant<=1].index.tolist()\nif const_cols:\n    df.drop(columns=const_cols, inplace=True)\n\n# 1.3 Train/Test ayÄ±r\ntrain_df = df[df[\"__split__\"]==\"train\"].copy()\ntest_df  = df[df[\"__split__\"]==\"test\"].copy()\nX_train, y_train = train_df.drop(columns=META), train_df[TARGET].astype(str)\nX_test,  y_test  = test_df.drop(columns=META),  test_df[TARGET].astype(str)\n\nprint(\"YÃ¼klendi âœ“\",\n      \"\\nTrain:\", X_train.shape, \"| Test:\", X_test.shape,\n      \"\\nTrain sÄ±nÄ±flarÄ±:\", sorted(y_train.unique()),\n      \"\\nTest  sÄ±nÄ±flarÄ±:\", sorted(y_test.unique()))","metadata":{"_uuid":"eee84e43-0835-4c02-bf96-e46f9b4303bf","_cell_guid":"aed33c85-0690-47cf-a68b-b7eb0094027e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-03T14:54:51.203943Z","iopub.execute_input":"2025-11-03T14:54:51.204267Z","iopub.status.idle":"2025-11-03T14:54:53.408144Z","shell.execute_reply.started":"2025-11-03T14:54:51.204246Z","shell.execute_reply":"2025-11-03T14:54:53.407135Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"YÃ¼klendi âœ“ \nTrain: (125170, 65) | Test: (306201, 65) \nTrain sÄ±nÄ±flarÄ±: ['LDAP', 'MSSQL', 'NetBIOS', 'Portmap', 'Syn', 'UDP', 'UDPLag'] \nTest  sÄ±nÄ±flarÄ±: ['DNS', 'LDAP', 'MSSQL', 'NTP', 'NetBIOS', 'SNMP', 'Syn', 'TFTP', 'UDP', 'UDPLag']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# AdÄ±m 2: Ortak sÄ±nÄ±flar (closed-set)\ncommon = sorted(set(y_train.unique()).intersection(set(y_test.unique())))\ntrain_mask = y_train.isin(common)\ntest_mask  = y_test.isin(common)\n\nX_tr, y_tr = X_train[train_mask].copy(), y_train[train_mask].copy()\nX_te, y_te = X_test[test_mask].copy(),  y_test[test_mask].copy()\n\nprint(\"Ortak sÄ±nÄ±flar:\", common)\nprint(\"Yeni Train/Test:\", X_tr.shape, X_te.shape)","metadata":{"_uuid":"69925753-166a-4e54-a3c5-97ecbbaf48da","_cell_guid":"bc64fac1-1586-4f48-9de1-c38c738f2b80","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-03T14:54:53.410052Z","iopub.execute_input":"2025-11-03T14:54:53.410421Z","iopub.status.idle":"2025-11-03T14:54:53.517996Z","shell.execute_reply.started":"2025-11-03T14:54:53.410398Z","shell.execute_reply":"2025-11-03T14:54:53.517018Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Ortak sÄ±nÄ±flar: ['LDAP', 'MSSQL', 'NetBIOS', 'Syn', 'UDP', 'UDPLag']\nYeni Train/Test: (120065, 65) (38973, 65)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# AdÄ±m 3: Manuel undersampling (imblearn yok)\nfrom collections import Counter\ntmp = X_tr.copy(); tmp[TARGET]=y_tr.values\nmin_count = tmp[TARGET].value_counts().min()\nbalanced = (tmp.groupby(TARGET, group_keys=False)\n              .apply(lambda x: x.sample(min_count, random_state=RANDOM_STATE)))\ny_tr_bal = balanced[TARGET].astype(str)\nX_tr_bal = balanced.drop(columns=TARGET)\n\nprint(\"Dengeleme Ã¶nce:\", Counter(y_tr))\nprint(\"Dengeleme sonra:\", Counter(y_tr_bal))\nprint(\"Yeni eÄŸitim boyutu:\", X_tr_bal.shape)","metadata":{"_uuid":"2af037f4-75e0-4ff7-b1e6-b49d70344525","_cell_guid":"ae2497c3-b836-4379-b426-a40bd9c1963c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-03T14:54:53.519094Z","iopub.execute_input":"2025-11-03T14:54:53.519483Z","iopub.status.idle":"2025-11-03T14:54:53.612771Z","shell.execute_reply.started":"2025-11-03T14:54:53.519449Z","shell.execute_reply":"2025-11-03T14:54:53.611763Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Dengeleme Ã¶nce: Counter({'Syn': 70336, 'UDP': 17770, 'UDPLag': 12639, 'MSSQL': 10974, 'LDAP': 6715, 'NetBIOS': 1631})\nDengeleme sonra: Counter({'LDAP': 1631, 'MSSQL': 1631, 'NetBIOS': 1631, 'Syn': 1631, 'UDP': 1631, 'UDPLag': 1631})\nYeni eÄŸitim boyutu: (9786, 65)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# --- AdÄ±m 4 (final patch): mutual_info_score ile manuel Ã¶zellik seÃ§imi + LGBM ---\nimport numpy as np, pandas as pd\nfrom sklearn.metrics import mutual_info_score\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom lightgbm import LGBMClassifier\n\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\n\ndef mi_scores(X, y):\n    \"\"\"Her sÃ¼tun iÃ§in mutual information puanÄ± hesapla (saf sklearn.metrics)\"\"\"\n    scores = {}\n    y_enc = pd.factorize(y)[0]\n    for col in X.columns:\n        # SÃ¼rekli deÄŸiÅŸkenleri kategoriye bÃ¶lmek iÃ§in kÃ¼Ã§Ã¼k quantile binning\n        x_bin = pd.qcut(X[col].rank(method=\"first\"), q=10, duplicates=\"drop\")\n        x_enc = pd.factorize(x_bin)[0]\n        mi = mutual_info_score(x_enc, y_enc)\n        scores[col] = mi\n    return pd.Series(scores).sort_values(ascending=False)\n\n# MI puanlarÄ±nÄ± hesapla\nmi = mi_scores(X_tr_bal, y_tr_bal)\nprint(\"En yÃ¼ksek bilgiye sahip 10 Ã¶zellik:\")\nprint(mi.head(10))\n\n# k deÄŸerleri listesi\nk_list = [15, 25, 35, 50]\ncv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n\nbest_k, best_cv, selected_cols = None, -1.0, None\n\nfor k in k_list:\n    top_cols = mi.head(k).index\n    X_sel = X_tr_bal[top_cols]\n    clf = LGBMClassifier(\n        n_estimators=200, learning_rate=0.1,\n        num_leaves=31, subsample=0.8, colsample_bytree=0.8,\n        random_state=RANDOM_STATE, n_jobs=-1, verbosity=-1\n    )\n    acc = cross_val_score(clf, X_sel, y_tr_bal, cv=cv, scoring=\"accuracy\").mean()\n    print(f\"k={k:2d} | CV Acc={acc:.4f}\")\n    if acc > best_cv:\n        best_cv, best_k, selected_cols = acc, k, top_cols\n\nprint(f\"\\nâœ… En iyi k={best_k} (CV Acc={best_cv:.4f})\")\nprint(\"SeÃ§ilen ilk 10 Ã¶zellik:\", list(selected_cols[:10]))\n\n# seÃ§ilen kolonlarla train/test setleri\nX_tr_sel = X_tr_bal[selected_cols].copy()\nX_te_sel = X_te[selected_cols].copy()","metadata":{"_uuid":"d11acdb7-ce44-4f85-aecc-794399d4058b","_cell_guid":"18071190-9fb2-4e4a-a5ee-d2f268f3c2fe","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-03T14:54:53.614388Z","iopub.execute_input":"2025-11-03T14:54:53.614732Z","iopub.status.idle":"2025-11-03T14:55:24.244322Z","shell.execute_reply.started":"2025-11-03T14:54:53.614709Z","shell.execute_reply":"2025-11-03T14:55:24.243437Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"En yÃ¼ksek bilgiye sahip 10 Ã¶zellik:\nSYN Flag Count           1.524883\nCWE Flag Count           1.405789\nRST Flag Count           1.385206\nFwd PSH Flags            1.385206\nBwd Packet Length Std    1.377581\nACK Flag Count           1.339930\nActive Min               1.300542\nProtocol                 1.294937\nActive Std               1.292313\nIdle Std                 1.291538\ndtype: float64\nk=15 | CV Acc=0.3732\nk=25 | CV Acc=0.5504\nk=35 | CV Acc=0.6403\nk=50 | CV Acc=0.6605\n\nâœ… En iyi k=50 (CV Acc=0.6605)\nSeÃ§ilen ilk 10 Ã¶zellik: ['SYN Flag Count', 'CWE Flag Count', 'RST Flag Count', 'Fwd PSH Flags', 'Bwd Packet Length Std', 'ACK Flag Count', 'Active Min', 'Protocol', 'Active Std', 'Idle Std']\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# === TAM VERÄ° HAZIRLIK (CIC-DDoS + dengeleme + Ã¶zellik seÃ§imi) ===\nimport os, glob, warnings, numpy as np, pandas as pd\nfrom collections import Counter\nfrom sklearn.metrics import mutual_info_score\nwarnings.filterwarnings(\"ignore\")\n\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\nDATA_DIR = \"/kaggle/input/cicddos2019\"\nTARGET = \"__label__\"\n\n# --- 1. Veri yÃ¼kleme ---\ndef infer_label(fname):  # Syn-training.parquet -> Syn\n    return os.path.basename(fname).split(\"-\")[0]\n\ndef infer_split(fname):  # train/test bilgisi\n    b = os.path.basename(fname).lower()\n    return \"train\" if \"train\" in b else (\"test\" if \"test\" in b else \"unknown\")\n\nframes = []\nfor f in sorted(glob.glob(os.path.join(DATA_DIR, \"*.parquet\"))):\n    df = pd.read_parquet(f)\n    df[\"__split__\"] = infer_split(f)\n    df[TARGET] = infer_label(f)\n    frames.append(df)\n\nraw = pd.concat(frames, ignore_index=True)\nraw = raw.replace([np.inf, -np.inf], np.nan)\n\n# --- 2. SÃ¼tun temizliÄŸi ---\nMETA = [TARGET, \"__split__\"]\nfeatures = [c for c in raw.columns if c not in META]\nnum_cols = [c for c in features if pd.api.types.is_numeric_dtype(raw[c])]\ndf = raw.drop(columns=[c for c in features if c not in num_cols]).copy()\n\nconstant = df[num_cols].nunique(dropna=False)\nconst_cols = constant[constant <= 1].index.tolist()\nif const_cols:\n    df.drop(columns=const_cols, inplace=True)\n\n# --- 3. Train/Test ayÄ±r ---\ntrain_df = df[df[\"__split__\"] == \"train\"].copy()\ntest_df = df[df[\"__split__\"] == \"test\"].copy()\nX_train, y_train = train_df.drop(columns=META), train_df[TARGET].astype(str)\nX_test, y_test = test_df.drop(columns=META), test_df[TARGET].astype(str)\n\nprint(\"YÃ¼klendi âœ“\")\nprint(\"Train:\", X_train.shape, \"| Test:\", X_test.shape)\n\n# --- 4. Closed-set filtreleme ---\ncommon = sorted(set(y_train.unique()).intersection(set(y_test.unique())))\ntrain_mask = y_train.isin(common)\ntest_mask = y_test.isin(common)\nX_tr = X_train[train_mask].copy()\ny_tr = y_train[train_mask].copy()\nX_te = X_test[test_mask].copy()\ny_te = y_test[test_mask].copy()\nprint(\"Ortak sÄ±nÄ±flar:\", common)\n\n# --- 5. Manuel dengeleme (undersampling) ---\ntmp = X_tr.copy()\ntmp[\"__y__\"] = y_tr.values\nmin_count = tmp[\"__y__\"].value_counts().min()\nbalanced = tmp.groupby(\"__y__\", group_keys=False).apply(\n    lambda x: x.sample(min_count, random_state=RANDOM_STATE)\n)\ny_tr_bal = balanced[\"__y__\"].astype(str)\nX_tr_bal = balanced.drop(columns=\"__y__\")\nprint(\"Denge sonrasÄ± boyut:\", X_tr_bal.shape)\n\n# --- 6. Ã–zellik seÃ§imi (Mutual Information ile) ---\ndef mi_scores(X, y):\n    scores = {}\n    y_enc = pd.factorize(y)[0]\n    for col in X.columns:\n        x_bin = pd.qcut(X[col].rank(method=\"first\"), q=10, duplicates=\"drop\")\n        x_enc = pd.factorize(x_bin)[0]\n        scores[col] = mutual_info_score(x_enc, y_enc)\n    return pd.Series(scores).sort_values(ascending=False)\n\nmi = mi_scores(X_tr_bal, y_tr_bal)\nselected_cols = mi.head(25).index\nX_tr_sel = X_tr_bal[selected_cols].copy()\nX_te_sel = X_te[selected_cols].copy()\n\nprint(\"\\nâœ… Veri tamamen hazÄ±r!\")\nprint(\"EÄŸitim:\", X_tr_sel.shape, \"| Test:\", X_te_sel.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T11:26:16.112215Z","iopub.execute_input":"2025-11-04T11:26:16.112995Z","iopub.status.idle":"2025-11-04T11:26:19.100538Z","shell.execute_reply.started":"2025-11-04T11:26:16.112956Z","shell.execute_reply":"2025-11-04T11:26:19.099604Z"}},"outputs":[{"name":"stdout","text":"YÃ¼klendi âœ“\nTrain: (125170, 65) | Test: (306201, 65)\nOrtak sÄ±nÄ±flar: ['LDAP', 'MSSQL', 'NetBIOS', 'Syn', 'UDP', 'UDPLag']\nDenge sonrasÄ± boyut: (9786, 65)\n\nâœ… Veri tamamen hazÄ±r!\nEÄŸitim: (9786, 25) | Test: (38973, 25)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# === GeliÅŸtirilmiÅŸ MBO: Acc-F1 fitness + k (Ã¶zellik sayÄ±sÄ±) optimizasyonu ===\nimport numpy as np, pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, f1_score, mutual_info_score\nfrom lightgbm import LGBMClassifier\nfrom sklearn.utils import check_random_state\n\nRANDOM_STATE = 42\nrng = check_random_state(RANDOM_STATE)\n\n# --- MI puanlarÄ±nÄ± hesapla (Ã¶zellik sayÄ±sÄ± k'yÄ± MBO seÃ§ecek) ---\ndef mi_scores(X, y, q=10):\n    scores = {}\n    y_enc = pd.factorize(y)[0]\n    for col in X.columns:\n        x_bin = pd.qcut(X[col].rank(method=\"first\"), q=q, duplicates=\"drop\")\n        x_enc = pd.factorize(x_bin)[0]\n        scores[col] = mutual_info_score(x_enc, y_enc)\n    return pd.Series(scores).sort_values(ascending=False)\n\nmi_series = mi_scores(X_tr_bal, y_tr_bal)\n\n# --- Arama alanlarÄ± (LightGBM + k) ---\nbounds = {\n    \"learning_rate\": (0.02, 0.2),\n    \"num_leaves\": (31, 255),\n    \"max_depth\": (6, 32),\n    \"subsample\": (0.6, 1.0),\n    \"colsample_bytree\": (0.6, 1.0),\n    \"min_child_samples\": (10, 100),\n    \"reg_alpha\": (0.0, 1.0),\n    \"reg_lambda\": (0.0, 2.0),\n    \"n_estimators\": (200, 1200),\n    \"k_feats\": (20, 60)\n}\nint_keys = [\"num_leaves\", \"max_depth\", \"min_child_samples\", \"n_estimators\", \"k_feats\"]\n\ndef clamp_cast(p):\n    pp = {}\n    for k,(lo,hi) in bounds.items():\n        v = max(lo, min(hi, p[k]))\n        if k in int_keys:\n            v = int(round(v))\n        pp[k] = v\n    return pp\n\ndef sample_params():\n    p = {k: rng.uniform(lo, hi) for k,(lo,hi) in bounds.items()}\n    return clamp_cast(p)\n\n# --- Fitness fonksiyonu: birleÅŸik skor (0.5*Acc + 0.5*F1) ---\ndef fitness_score(params):\n    params = clamp_cast(params)\n    k = params.pop(\"k_feats\")\n    cols = mi_series.head(k).index\n    X = X_tr_bal[cols].values\n    y = y_tr_bal.values\n\n    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n    accs, f1s = [], []\n\n    for tr_idx, va_idx in cv.split(X, y):\n        Xtr, Xva = X[tr_idx], X[va_idx]\n        ytr, yva = y[tr_idx], y[va_idx]\n\n        clf = LGBMClassifier(\n            random_state=RANDOM_STATE,\n            class_weight=\"balanced\",\n            verbose=-1,\n            n_jobs=1,\n            **params\n        )\n\n        clf.fit(Xtr, ytr)\n        yhat = clf.predict(Xva)\n\n        accs.append(accuracy_score(yva, yhat))\n        f1s.append(f1_score(yva, yhat, average=\"macro\"))\n\n    acc = float(np.mean(accs))\n    f1m = float(np.mean(f1s))\n    return 0.5*acc + 0.5*f1m, acc, f1m, cols\n\n# --- MBO parametreleri ---\npop_size = 12\nn_gen = 8\nattract = 0.35\nflight = 0.08\nmut_p = 0.15\n\n# --- BaÅŸlat ---\npopulation = [sample_params() for _ in range(pop_size)]\nscores, details = [], []\n\nfor p in population:\n    s, a, f, cols = fitness_score(p)\n    scores.append(s)\n    details.append((a, f, cols))\n\nscores = np.array(scores)\nbest_idx = int(np.argmax(scores))\nbest_p = population[best_idx].copy()\nbest_s = float(scores[best_idx])\nbest_acc, best_f1, best_cols = details[best_idx]\n\nprint(f\"BaÅŸlangÄ±Ã§ | Score={best_s:.4f} (Acc={best_acc:.4f}, F1={best_f1:.4f}), k={len(best_cols)}\")\n\n# --- Ana dÃ¶ngÃ¼ ---\nfor g in range(n_gen):\n    new_pop = []\n    for i in range(pop_size):\n        p = population[i].copy()\n        for k,(lo,hi) in bounds.items():\n            if rng.rand() < mut_p:\n                p[k] = p[k] + rng.uniform(-0.1,0.1)*(hi-lo)\n        new_pop.append(clamp_cast(p))\n\n    for i in range(pop_size):\n        for k,(lo,hi) in bounds.items():\n            delta = best_p[k] - new_pop[i][k]\n            new_pop[i][k] = new_pop[i][k] + attract*delta + rng.uniform(-flight, flight)\n        new_pop[i] = clamp_cast(new_pop[i])\n\n    scores, details = [], []\n    for p in new_pop:\n        s, a, f, cols = fitness_score(p)\n        scores.append(s)\n        details.append((a, f, cols))\n\n    scores = np.array(scores)\n    gen_best = int(np.argmax(scores))\n    if scores[gen_best] > best_s:\n        best_s = float(scores[gen_best])\n        best_p = new_pop[gen_best].copy()\n        best_acc, best_f1, best_cols = details[gen_best]\n\n    population = new_pop\n    print(f\"Nesil {g+1}/{n_gen} | Score={best_s:.4f} (Acc={best_acc:.4f}, F1={best_f1:.4f}), k={len(best_cols)}\")\n\nprint(\"\\nâœ… MBO bitti.\")\nprint(\"En iyi parametreler:\")\nfor k,v in best_p.items():\n    print(f\" - {k}: {v}\")\n\n# --- Nihai test ---\nX_tr_final = X_tr_bal[best_cols].values\nX_te_final = X_te[best_cols].values\n\nfinal = LGBMClassifier(\n    random_state=RANDOM_STATE,\n    class_weight=\"balanced\",\n    verbose=-1,\n    n_jobs=-1,\n    **{kk:vv for kk,vv in best_p.items() if kk!='k_feats'}\n).fit(X_tr_final, y_tr_bal)\n\ny_pred = final.predict(X_te_final)\nacc = accuracy_score(y_te, y_pred)\nf1m = f1_score(y_te, y_pred, average=\"macro\")\n\nprint(f\"\\nðŸ“Š TEST (MBO+Balanced+best_k={len(best_cols)})\")\nprint(f\"Accuracy = {acc:.4f}\")\nprint(f\"Macro-F1 = {f1m:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T11:59:22.674808Z","iopub.execute_input":"2025-11-04T11:59:22.675187Z","iopub.status.idle":"2025-11-04T13:31:15.235793Z","shell.execute_reply.started":"2025-11-04T11:59:22.675163Z","shell.execute_reply":"2025-11-04T13:31:15.234635Z"}},"outputs":[{"name":"stdout","text":"BaÅŸlangÄ±Ã§ | Score=0.6515 (Acc=0.6544, F1=0.6486), k=42\nNesil 1/8 | Score=0.6607 (Acc=0.6642, F1=0.6572), k=51\nNesil 2/8 | Score=0.6643 (Acc=0.6680, F1=0.6606), k=51\nNesil 3/8 | Score=0.6643 (Acc=0.6680, F1=0.6606), k=51\nNesil 4/8 | Score=0.6646 (Acc=0.6681, F1=0.6610), k=48\nNesil 5/8 | Score=0.6646 (Acc=0.6681, F1=0.6610), k=48\nNesil 6/8 | Score=0.6648 (Acc=0.6684, F1=0.6613), k=47\nNesil 7/8 | Score=0.6659 (Acc=0.6696, F1=0.6622), k=49\nNesil 8/8 | Score=0.6659 (Acc=0.6696, F1=0.6622), k=49\n\nâœ… MBO bitti.\nEn iyi parametreler:\n - learning_rate: 0.02\n - num_leaves: 87\n - max_depth: 27\n - subsample: 0.9595193455783716\n - colsample_bytree: 0.6638216465257722\n - min_child_samples: 72\n - reg_alpha: 0.3811980548222325\n - reg_lambda: 0.9057365751040158\n - n_estimators: 633\n - k_feats: 49\n\nðŸ“Š TEST (MBO+Balanced+best_k=49)\nAccuracy = 0.5247\nMacro-F1 = 0.4560\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# === AdÄ±m 8: MBO + XGBoost hiperparametre optimizasyonu (LabelEncoder + dÃ¼zgÃ¼n hizalÄ± sÃ¼rÃ¼m) ===\nimport numpy as np, pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import XGBClassifier\nfrom sklearn.utils import check_random_state\n\nRANDOM_STATE = 42\nrng = check_random_state(RANDOM_STATE)\ncv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n\n# --- Etiketleri sayÄ±sallaÅŸtÄ±r (XGBoost bunu ister) ---\nlabel_enc = LabelEncoder()\ny_tr_bal_enc = label_enc.fit_transform(y_tr_bal)\ny_te_enc = label_enc.transform(y_te)\n\n# --- Parametre aralÄ±klarÄ± (XGBoost) ---\nbounds = {\n    \"learning_rate\": (0.01, 0.3),\n    \"max_depth\": (3, 15),\n    \"min_child_weight\": (1, 10),\n    \"subsample\": (0.6, 1.0),\n    \"colsample_bytree\": (0.6, 1.0),\n    \"gamma\": (0, 5),\n    \"reg_lambda\": (0.5, 3),\n    \"n_estimators\": (200, 1000),\n    \"k_feats\": (20, 60)\n}\nint_keys = [\"max_depth\", \"min_child_weight\", \"n_estimators\", \"k_feats\"]\n\ndef clamp_cast(p):\n    pp = {}\n    for k, (lo, hi) in bounds.items():\n        v = max(lo, min(hi, p[k]))\n        if k in int_keys:\n            v = int(round(v))\n        pp[k] = v\n    return pp\n\ndef sample_params():\n    p = {k: rng.uniform(lo, hi) for k, (lo, hi) in bounds.items()}\n    return clamp_cast(p)\n\n# --- Fitness fonksiyonu (Accuracy + F1) / 2 ---\ndef fitness_score(params):\n    params = clamp_cast(params)\n    k = params.pop(\"k_feats\")\n    cols = mi_series.head(k).index\n    X = X_tr_bal[cols].values\n    y = y_tr_bal_enc\n\n    accs, f1s = [], []\n    for tr_idx, va_idx in cv.split(X, y):\n        Xtr, Xva = X[tr_idx], X[va_idx]\n        ytr, yva = y[tr_idx], y[va_idx]\n\n        clf = XGBClassifier(\n            random_state=RANDOM_STATE,\n            n_jobs=1,\n            tree_method=\"hist\",\n            objective=\"multi:softmax\",\n            num_class=len(np.unique(y_tr_bal_enc)),\n            eval_metric=\"mlogloss\",\n            verbosity=0,\n            **params\n        )\n\n        clf.fit(Xtr, ytr)\n        yhat = clf.predict(Xva)\n\n        accs.append(accuracy_score(yva, yhat))\n        f1s.append(f1_score(yva, yhat, average=\"macro\"))\n\n    acc = float(np.mean(accs))\n    f1m = float(np.mean(f1s))\n    return 0.5 * acc + 0.5 * f1m, acc, f1m, cols\n\n# --- MBO ayarlarÄ± ---\npop_size = 12\nn_gen = 8\nattract = 0.35\nflight = 0.08\nmut_p = 0.15\n\n# --- PopÃ¼lasyon baÅŸlat ---\npopulation = [sample_params() for _ in range(pop_size)]\nscores, details = [], []\n\nfor p in population:\n    s, a, f, cols = fitness_score(p)\n    scores.append(s)\n    details.append((a, f, cols))\n\nscores = np.array(scores)\nbest_idx = int(np.argmax(scores))\nbest_p = population[best_idx].copy()\nbest_s = float(scores[best_idx])\nbest_acc, best_f1, best_cols = details[best_idx]\n\nprint(f\"BaÅŸlangÄ±Ã§ | Score={best_s:.4f} (Acc={best_acc:.4f}, F1={best_f1:.4f}), k={len(best_cols)}\")\n\n# --- MBO ana dÃ¶ngÃ¼sÃ¼ ---\nfor g in range(n_gen):\n    new_pop = []\n    for i in range(pop_size):\n        p = population[i].copy()\n        for k, (lo, hi) in bounds.items():\n            if rng.rand() < mut_p:\n                p[k] = p[k] + rng.uniform(-0.1, 0.1) * (hi - lo)\n        new_pop.append(clamp_cast(p))\n\n    for i in range(pop_size):\n        for k, (lo, hi) in bounds.items():\n            delta = best_p[k] - new_pop[i][k]\n            new_pop[i][k] = new_pop[i][k] + attract * delta + rng.uniform(-flight, flight)\n        new_pop[i] = clamp_cast(new_pop[i])\n\n    scores, details = [], []\n    for p in new_pop:\n        s, a, f, cols = fitness_score(p)\n        scores.append(s)\n        details.append((a, f, cols))\n\n    scores = np.array(scores)\n    gen_best = int(np.argmax(scores))\n    if scores[gen_best] > best_s:\n        best_s = float(scores[gen_best])\n        best_p = new_pop[gen_best].copy()\n        best_acc, best_f1, best_cols = details[gen_best]\n\n    population = new_pop\n    print(f\"Nesil {g+1}/{n_gen} | Score={best_s:.4f} (Acc={best_acc:.4f}, F1={best_f1:.4f}), k={len(best_cols)}\")\n\nprint(\"\\nâœ… MBO + XGBoost tamamlandÄ±.\")\nprint(\"En iyi parametreler:\")\nfor k, v in best_p.items():\n    print(f\" - {k}: {v}\")\n\n# --- Nihai test ---\nX_tr_final = X_tr_bal[best_cols].values\nX_te_final = X_te[best_cols].values\n\nfinal = XGBClassifier(\n    random_state=RANDOM_STATE,\n    n_jobs=-1,\n    tree_method=\"hist\",\n    objective=\"multi:softmax\",\n    num_class=len(np.unique(y_tr_bal_enc)),\n    eval_metric=\"mlogloss\",\n    verbosity=0,\n    **{kk: vv for kk, vv in best_p.items() if kk != \"k_feats\"}\n).fit(X_tr_final, y_tr_bal_enc)\n\ny_pred_enc = final.predict(X_te_final)\ny_pred = label_enc.inverse_transform(y_pred_enc)\n\nacc = accuracy_score(y_te, y_pred)\nf1m = f1_score(y_te, y_pred, average=\"macro\")\n\nprint(f\"\\nðŸ“Š TEST (MBO + XGBoost + best_k={len(best_cols)})\")\nprint(f\"Accuracy = {acc:.4f}\")\nprint(f\"Macro-F1 = {f1m:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T14:22:22.171695Z","iopub.execute_input":"2025-11-04T14:22:22.172109Z","iopub.status.idle":"2025-11-04T14:50:16.776990Z","shell.execute_reply.started":"2025-11-04T14:22:22.172080Z","shell.execute_reply":"2025-11-04T14:50:16.775959Z"}},"outputs":[{"name":"stdout","text":"BaÅŸlangÄ±Ã§ | Score=0.6674 (Acc=0.6712, F1=0.6637), k=44\nNesil 1/8 | Score=0.6674 (Acc=0.6712, F1=0.6637), k=44\nNesil 2/8 | Score=0.6697 (Acc=0.6740, F1=0.6653), k=49\nNesil 3/8 | Score=0.6697 (Acc=0.6740, F1=0.6653), k=49\nNesil 4/8 | Score=0.6697 (Acc=0.6740, F1=0.6653), k=49\nNesil 5/8 | Score=0.6697 (Acc=0.6740, F1=0.6653), k=49\nNesil 6/8 | Score=0.6697 (Acc=0.6740, F1=0.6653), k=49\nNesil 7/8 | Score=0.6697 (Acc=0.6740, F1=0.6653), k=49\nNesil 8/8 | Score=0.6697 (Acc=0.6740, F1=0.6653), k=49\n\nâœ… MBO + XGBoost tamamlandÄ±.\nEn iyi parametreler:\n - learning_rate: 0.13708630408502848\n - max_depth: 14\n - min_child_weight: 5\n - subsample: 0.8020186825666225\n - colsample_bytree: 0.6719067711227534\n - gamma: 1.2511997872425664\n - reg_lambda: 1.0593203229409496\n - n_estimators: 681\n - k_feats: 49\n\nðŸ“Š TEST (MBO + XGBoost + best_k=49)\nAccuracy = 0.5229\nMacro-F1 = 0.4542\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}