{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4059918,"sourceType":"datasetVersion","datasetId":2398189}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ADIM 0: Kurulum\nimport os, glob, warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\n\nfrom collections import Counter\n\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\n\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\n\nDATA_DIR = \"/kaggle/input/cicddos2019\"\nTARGET   = \"__label__\"\n\nprint(\"ADIM 0 hazÄ±r âœ”\")\n","metadata":{"_uuid":"c7fabda5-4b09-4ee5-b321-df201d2a9671","_cell_guid":"60e13090-dec8-4f49-87d6-f0e2e3cc636b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-18T08:13:37.626524Z","iopub.execute_input":"2025-11-18T08:13:37.626822Z","iopub.status.idle":"2025-11-18T08:13:37.633336Z","shell.execute_reply.started":"2025-11-18T08:13:37.626803Z","shell.execute_reply":"2025-11-18T08:13:37.632401Z"}},"outputs":[{"name":"stdout","text":"ADIM 0 hazÄ±r âœ”\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ADIM 1: CIC-DDoS verisini yÃ¼kleme + sÃ¼tun temizliÄŸi\n\ndef infer_label(fname):\n    # Syn-training.parquet -> Syn\n    return os.path.basename(fname).split(\"-\")[0]\n\ndef infer_split(fname):\n    b = os.path.basename(fname).lower()\n    if \"train\" in b:\n        return \"train\"\n    elif \"test\" in b:\n        return \"test\"\n    else:\n        return \"unknown\"\n\nframes = []\nfor f in sorted(glob.glob(os.path.join(DATA_DIR, \"*.parquet\"))):\n    df = pd.read_parquet(f)\n    df[\"__split__\"] = infer_split(f)\n    df[TARGET]      = infer_label(f)\n    frames.append(df)\n\nraw = pd.concat(frames, ignore_index=True)\nraw = raw.replace([np.inf, -np.inf], np.nan)\n\nMETA     = [TARGET, \"__split__\"]\nfeatures = [c for c in raw.columns if c not in META]\nnum_cols = [c for c in features if pd.api.types.is_numeric_dtype(raw[c])]\n\n# Sadece sayÄ±sal Ã¶zellikleri tut\ndf = raw.drop(columns=[c for c in features if c not in num_cols]).copy()\n\n# Sabit sÃ¼tunlarÄ± at\nnunique = df[num_cols].nunique(dropna=False)\nconst_cols = nunique[nunique <= 1].index.tolist()\nif const_cols:\n    df.drop(columns=const_cols, inplace=True)\n\n# Train/Test ayÄ±r\ntrain_df = df[df[\"__split__\"] == \"train\"].copy()\ntest_df  = df[df[\"__split__\"] == \"test\"].copy()\n\nX_train = train_df.drop(columns=META)\ny_train = train_df[TARGET].astype(str)\n\nX_test  = test_df.drop(columns=META)\ny_test  = test_df[TARGET].astype(str)\n\nprint(\"YÃ¼klendi âœ“\")\nprint(\"Train:\", X_train.shape, \"| Test:\", X_test.shape)\nprint(\"Train sÄ±nÄ±flarÄ±:\", sorted(y_train.unique()))\nprint(\"Test  sÄ±nÄ±flarÄ±:\", sorted(y_test.unique()))\n","metadata":{"_uuid":"bf271fb1-94fd-4d1d-829c-3e71d5e377b2","_cell_guid":"c6dad797-8c53-4331-876a-639b01b29ec2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-18T08:13:37.635226Z","iopub.execute_input":"2025-11-18T08:13:37.635515Z","iopub.status.idle":"2025-11-18T08:13:39.144326Z","shell.execute_reply.started":"2025-11-18T08:13:37.635498Z","shell.execute_reply":"2025-11-18T08:13:39.143495Z"}},"outputs":[{"name":"stdout","text":"YÃ¼klendi âœ“\nTrain: (125170, 65) | Test: (306201, 65)\nTrain sÄ±nÄ±flarÄ±: ['LDAP', 'MSSQL', 'NetBIOS', 'Portmap', 'Syn', 'UDP', 'UDPLag']\nTest  sÄ±nÄ±flarÄ±: ['DNS', 'LDAP', 'MSSQL', 'NTP', 'NetBIOS', 'SNMP', 'Syn', 'TFTP', 'UDP', 'UDPLag']\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ADIM 2: Closed-set (ortak sÄ±nÄ±flar) + manuel undersampling\n\ncommon = sorted(set(y_train.unique()).intersection(set(y_test.unique())))\ntrain_mask = y_train.isin(common)\ntest_mask  = y_test.isin(common)\n\nX_tr = X_train[train_mask].copy()\ny_tr = y_train[train_mask].copy()\n\nX_te = X_test[test_mask].copy()\ny_te = y_test[test_mask].copy()\n\nprint(\"Ortak sÄ±nÄ±flar:\", common)\nprint(\"Yeni Train/Test:\", X_tr.shape, X_te.shape)\n\n# Manuel undersampling\ntmp = X_tr.copy()\ntmp[\"__y__\"] = y_tr.values\nmin_count = tmp[\"__y__\"].value_counts().min()\n\nbalanced = tmp.groupby(\"__y__\", group_keys=False).apply(\n    lambda x: x.sample(min_count, random_state=RANDOM_STATE)\n)\n\ny_tr_bal = balanced[\"__y__\"].astype(str)\nX_tr_bal = balanced.drop(columns=\"__y__\")\n\nprint(\"\\nDengeleme Ã¶nce:\", Counter(y_tr))\nprint(\"Dengeleme sonra:\", Counter(y_tr_bal))\nprint(\"Yeni eÄŸitim boyutu:\", X_tr_bal.shape)\n","metadata":{"_uuid":"a23064c0-2a05-49b8-b773-cc3650d309f9","_cell_guid":"d379a593-4982-4204-8e46-69a903d21c0d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-18T08:13:39.145338Z","iopub.execute_input":"2025-11-18T08:13:39.145619Z","iopub.status.idle":"2025-11-18T08:13:39.285602Z","shell.execute_reply.started":"2025-11-18T08:13:39.145600Z","shell.execute_reply":"2025-11-18T08:13:39.284725Z"}},"outputs":[{"name":"stdout","text":"Ortak sÄ±nÄ±flar: ['LDAP', 'MSSQL', 'NetBIOS', 'Syn', 'UDP', 'UDPLag']\nYeni Train/Test: (120065, 65) (38973, 65)\n\nDengeleme Ã¶nce: Counter({'Syn': 70336, 'UDP': 17770, 'UDPLag': 12639, 'MSSQL': 10974, 'LDAP': 6715, 'NetBIOS': 1631})\nDengeleme sonra: Counter({'LDAP': 1631, 'MSSQL': 1631, 'NetBIOS': 1631, 'Syn': 1631, 'UDP': 1631, 'UDPLag': 1631})\nYeni eÄŸitim boyutu: (9786, 65)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ADIM 3: LabelEncoder (tÃ¼m optimizasyonlarda bunu kullanacaÄŸÄ±z)\n\nlabel_enc = LabelEncoder()\ny_tr_bal_enc = label_enc.fit_transform(y_tr_bal)\ny_te_enc     = label_enc.transform(y_te)\n\nprint(\"SÄ±nÄ±f sayÄ±sÄ±:\", len(label_enc.classes_))\nprint(\"SÄ±nÄ±flar:\", list(label_enc.classes_))\n","metadata":{"_uuid":"bbcfc373-5026-48c1-82b2-38356546b70d","_cell_guid":"7ea263aa-30a6-4662-a548-958b50079946","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-18T08:13:39.286371Z","iopub.execute_input":"2025-11-18T08:13:39.286586Z","iopub.status.idle":"2025-11-18T08:13:39.300308Z","shell.execute_reply.started":"2025-11-18T08:13:39.286569Z","shell.execute_reply":"2025-11-18T08:13:39.299497Z"}},"outputs":[{"name":"stdout","text":"SÄ±nÄ±f sayÄ±sÄ±: 6\nSÄ±nÄ±flar: ['LDAP', 'MSSQL', 'NetBIOS', 'Syn', 'UDP', 'UDPLag']\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# ADIM 4: Baz modellerin karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ± (CV: 3-fold)\n\nfrom sklearn.compose import ColumnTransformer\n\nnumeric_features = X_tr_bal.columns.tolist()\npreprocess = ColumnTransformer(\n    [(\"num\", StandardScaler(), numeric_features)],\n    remainder=\"drop\"\n)\n\nmodels = {\n    \"NaiveBayes\": GaussianNB(),\n    \"LogReg\": LogisticRegression(max_iter=1000, n_jobs=-1),\n    \"DecisionTree\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1),\n    \"KNN\": KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n    \"GradBoost\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n    \"AdaBoost\": AdaBoostClassifier(random_state=RANDOM_STATE),\n    \"LightGBM\": LGBMClassifier(random_state=RANDOM_STATE, n_estimators=200, n_jobs=-1),\n    \"XGBoost\": XGBClassifier(\n        random_state=RANDOM_STATE,\n        n_estimators=200,\n        n_jobs=-1,\n        tree_method=\"hist\",\n        objective=\"multi:softmax\",\n        num_class=len(np.unique(y_tr_bal_enc)),\n        eval_metric=\"mlogloss\",\n        verbosity=0,\n    ),\n}\n\ncv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n\nprint(\"âœ… Baz modeller (3-fold CV, balanced data):\")\nbaseline_results = []\n\nfor name, clf in models.items():\n    pipe = Pipeline([\n        (\"prep\", preprocess),\n        (\"clf\", clf)\n    ])\n    acc = cross_val_score(pipe, X_tr_bal, y_tr_bal_enc, cv=cv, scoring=\"accuracy\").mean()\n    f1m = cross_val_score(pipe, X_tr_bal, y_tr_bal_enc, cv=cv, scoring=\"f1_macro\").mean()\n    baseline_results.append((name, acc, f1m))\n    print(f\"{name:10s} | Acc={acc:.4f} | F1-macro={f1m:.4f}\")\n\nbaseline_results = sorted(baseline_results, key=lambda x: x[1], reverse=True)\n","metadata":{"_uuid":"d9fbd353-b784-4419-8a89-d7f35b7344b6","_cell_guid":"6d3f03b6-a8ca-4bda-8eb8-3704da5ec261","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-18T08:13:39.302241Z","iopub.execute_input":"2025-11-18T08:13:39.302462Z","iopub.status.idle":"2025-11-18T08:17:46.009052Z","shell.execute_reply.started":"2025-11-18T08:13:39.302447Z","shell.execute_reply":"2025-11-18T08:17:46.008246Z"}},"outputs":[{"name":"stdout","text":"âœ… Baz modeller (3-fold CV, balanced data):\nNaiveBayes | Acc=0.4123 | F1-macro=0.3188\nLogReg     | Acc=0.5855 | F1-macro=0.5722\nDecisionTree | Acc=0.6087 | F1-macro=0.6082\nRandomForest | Acc=0.6540 | F1-macro=0.6481\nKNN        | Acc=0.6148 | F1-macro=0.6094\nGradBoost  | Acc=0.6661 | F1-macro=0.6558\nAdaBoost   | Acc=0.5029 | F1-macro=0.4603\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002792 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12351\n[LightGBM] [Info] Number of data points in the train set: 6524, number of used features: 64\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.791147\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.791147\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002746 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12343\n[LightGBM] [Info] Number of data points in the train set: 6524, number of used features: 64\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.791147\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.791147\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002928 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12369\n[LightGBM] [Info] Number of data points in the train set: 6524, number of used features: 64\n[LightGBM] [Info] Start training from score -1.791147\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.791147\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003280 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12351\n[LightGBM] [Info] Number of data points in the train set: 6524, number of used features: 64\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.791147\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.791147\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002930 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12343\n[LightGBM] [Info] Number of data points in the train set: 6524, number of used features: 64\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.791147\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.791147\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002852 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12369\n[LightGBM] [Info] Number of data points in the train set: 6524, number of used features: 64\n[LightGBM] [Info] Start training from score -1.791147\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.791147\n[LightGBM] [Info] Start training from score -1.792066\n[LightGBM] [Info] Start training from score -1.792066\nLightGBM   | Acc=0.6599 | F1-macro=0.6537\nXGBoost    | Acc=0.6586 | F1-macro=0.6526\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ADIM 5: Mutual Information ile Ã¶zellik Ã¶nem sÄ±ralamasÄ±\n\nfrom sklearn.metrics import mutual_info_score\n\ndef mi_scores(X, y_enc, q=10):\n    scores = {}\n    for col in X.columns:\n        ranks = X[col].rank(method=\"first\")\n        try:\n            bins = pd.qcut(ranks, q=q, duplicates=\"drop\")\n            enc = pd.factorize(bins)[0]\n            scores[col] = mutual_info_score(enc, y_enc)\n        except Exception:\n            scores[col] = 0.0\n    return pd.Series(scores).sort_values(ascending=False)\n\nmi_series = mi_scores(X_tr_bal, y_tr_bal_enc)\n\nprint(\"En yÃ¼ksek bilgiye sahip 10 Ã¶zellik:\")\nprint(mi_series.head(10))\n","metadata":{"_uuid":"cc81d692-f8ef-48b1-a6d2-c0594c223a45","_cell_guid":"73fe788a-4dbe-40a5-85fa-3f93fa7ea3d7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-18T08:17:46.009660Z","iopub.execute_input":"2025-11-18T08:17:46.009877Z","iopub.status.idle":"2025-11-18T08:17:46.414247Z","shell.execute_reply.started":"2025-11-18T08:17:46.009842Z","shell.execute_reply":"2025-11-18T08:17:46.413312Z"}},"outputs":[{"name":"stdout","text":"En yÃ¼ksek bilgiye sahip 10 Ã¶zellik:\nSYN Flag Count           1.524883\nCWE Flag Count           1.405789\nRST Flag Count           1.385206\nFwd PSH Flags            1.385206\nBwd Packet Length Std    1.377581\nACK Flag Count           1.339930\nActive Min               1.300542\nProtocol                 1.294937\nActive Std               1.292313\nIdle Std                 1.291538\ndtype: float64\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# ADIM 6 (GÃœNCEL): Sessiz MBO + LightGBM (log spam yok)\n\nimport contextlib, io\nfrom sklearn.utils import check_random_state\n\nrng = check_random_state(RANDOM_STATE)\n\n# --- LightGBM + k (Ã¶zellik sayÄ±sÄ±) arama alanÄ± ---\nbounds_lgbm = {\n    \"learning_rate\": (0.02, 0.2),\n    \"num_leaves\": (31, 255),\n    \"max_depth\": (6, 32),\n    \"subsample\": (0.6, 1.0),\n    \"colsample_bytree\": (0.6, 1.0),\n    \"min_child_samples\": (10, 100),\n    \"reg_alpha\": (0.0, 1.0),\n    \"reg_lambda\": (0.0, 2.0),\n    \"n_estimators\": (200, 800),\n    \"k_feats\": (20, 60),\n}\nint_keys_lgbm = [\"num_leaves\", \"max_depth\",\n                 \"min_child_samples\", \"n_estimators\", \"k_feats\"]\n\n\ndef clamp_lgbm(p):\n    out = {}\n    for k, (lo, hi) in bounds_lgbm.items():\n        v = max(lo, min(hi, p[k]))\n        if k in int_keys_lgbm:\n            v = int(round(v))\n        out[k] = v\n    return out\n\n\ndef sample_lgbm():\n    return clamp_lgbm({k: rng.uniform(lo, hi) for k, (lo, hi) in bounds_lgbm.items()})\n\n\ncv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n\ndef fitness_lgbm(p):\n    \"\"\"0.5*Acc + 0.5*Macro-F1 fitness, LightGBM Ã§Ä±ktÄ±larÄ±nÄ± sessize alÄ±r.\"\"\"\n    p = clamp_lgbm(p)\n    k = p[\"k_feats\"]\n    cols = mi_series.head(k).index          # ADIM 5'te hesaplanan MI sÄ±rasÄ±\n    X = X_tr_bal[cols].values\n    y = y_tr_bal_enc\n\n    accs, f1s = [], []\n\n    for tr_idx, va_idx in cv.split(X, y):\n        Xtr, Xva = X[tr_idx], X[va_idx]\n        ytr, yva = y[tr_idx], y[va_idx]\n\n        model = LGBMClassifier(\n            random_state=RANDOM_STATE,\n            n_jobs=1,\n            # lightgbm loglarÄ±nÄ± kapat\n            verbosity=-1\n        )\n\n        # TÃ¼m LightGBM Ã§Ä±ktÄ±sÄ±nÄ± yut (stdout + stderr)\n        buf_out, buf_err = io.StringIO(), io.StringIO()\n        with contextlib.redirect_stdout(buf_out), contextlib.redirect_stderr(buf_err):\n            model.set_params(**{kk: vv for kk, vv in p.items() if kk != \"k_feats\"})\n            model.fit(Xtr, ytr)\n\n        pred = model.predict(Xva)\n        accs.append(accuracy_score(yva, pred))\n        f1s.append(f1_score(yva, pred, average=\"macro\"))\n\n    acc = float(np.mean(accs))\n    f1m = float(np.mean(f1s))\n    score = 0.5 * acc + 0.5 * f1m\n    return score, acc, f1m, cols\n\n\n# --- MBO ayarlarÄ± ---\npop_size = 10\ngens     = 6\n\npopulation = [sample_lgbm() for _ in range(pop_size)]\nbest_s, best_p, best_cols = -1, None, None\nbest_acc = best_f1 = 0\n\nprint(\"MBO + LightGBM (sessiz) baÅŸlatÄ±lÄ±yor...\\n\")\n\n# BaÅŸlangÄ±Ã§ populasyonu\nfor p in population:\n    s, a, f, c = fitness_lgbm(p)\n    if s > best_s:\n        best_s, best_p, best_cols = s, p, c\n        best_acc, best_f1 = a, f\n\nprint(f\"BaÅŸlangÄ±Ã§ | Score={best_s:.4f} (Acc={best_acc:.4f}, F1={best_f1:.4f}), k={len(best_cols)}\")\n\n# --- Ana MBO dÃ¶ngÃ¼sÃ¼ ---\nfor g in range(gens):\n    new_pop = []\n    # Mutasyon\n    for p in population:\n        q = p.copy()\n        for k, (lo, hi) in bounds_lgbm.items():\n            if rng.rand() < 0.15:\n                q[k] += rng.uniform(-0.1, 0.1) * (hi - lo)\n        new_pop.append(clamp_lgbm(q))\n\n    # En iyi Ã§Ã¶zÃ¼me Ã§ekilme\n    for i in range(pop_size):\n        for k, (lo, hi) in bounds_lgbm.items():\n            delta = best_p[k] - new_pop[i][k]\n            new_pop[i][k] += 0.3 * delta + rng.uniform(-0.05, 0.05)\n        new_pop[i] = clamp_lgbm(new_pop[i])\n\n    # Yeni populasyonu deÄŸerlendir\n    for p in new_pop:\n        s, a, f, c = fitness_lgbm(p)\n        if s > best_s:\n            best_s, best_p, best_cols = s, p, c\n            best_acc, best_f1 = a, f\n\n    population = new_pop\n    print(f\"Nesil {g+1}/{gens} | Score={best_s:.4f} (Acc={best_acc:.4f}, F1={best_f1:.4f}), k={len(best_cols)}\")\n\nprint(\"\\nâœ… MBO + LightGBM (sessiz) bitti.\")\nprint(\"En iyi parametreler:\")\nfor k, v in best_p.items():\n    print(f\" - {k}: {v}\")\n","metadata":{"_uuid":"f51239a2-3c8a-4955-b6e3-17c1257b700f","_cell_guid":"723fefc3-6713-4317-94c5-0b4a3b32b8d8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-18T08:17:46.415380Z","iopub.execute_input":"2025-11-18T08:17:46.415714Z","iopub.status.idle":"2025-11-18T08:48:00.375666Z","shell.execute_reply.started":"2025-11-18T08:17:46.415683Z","shell.execute_reply":"2025-11-18T08:48:00.374766Z"}},"outputs":[{"name":"stdout","text":"MBO + LightGBM (sessiz) baÅŸlatÄ±lÄ±yor...\n\nBaÅŸlangÄ±Ã§ | Score=0.6499 (Acc=0.6523, F1=0.6475), k=59\nNesil 1/6 | Score=0.6499 (Acc=0.6523, F1=0.6475), k=59\nNesil 2/6 | Score=0.6557 (Acc=0.6595, F1=0.6520), k=39\nNesil 3/6 | Score=0.6577 (Acc=0.6609, F1=0.6545), k=52\nNesil 4/6 | Score=0.6670 (Acc=0.6708, F1=0.6632), k=50\nNesil 5/6 | Score=0.6696 (Acc=0.6734, F1=0.6657), k=46\nNesil 6/6 | Score=0.6701 (Acc=0.6740, F1=0.6662), k=45\n\nâœ… MBO + LightGBM (sessiz) bitti.\nEn iyi parametreler:\n - learning_rate: 0.02\n - num_leaves: 126\n - max_depth: 26\n - subsample: 0.8137200054769711\n - colsample_bytree: 0.754106945578895\n - min_child_samples: 58\n - reg_alpha: 0.2798538694889267\n - reg_lambda: 1.5044153110420453\n - n_estimators: 241\n - k_feats: 45\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# ADIM 7: Test setinde MBO + LightGBM performansÄ±\n\nX_tr_final = X_tr_bal[best_cols].values\nX_te_final = X_te[best_cols].values\n\nfinal_lgbm = LGBMClassifier(\n    random_state=RANDOM_STATE,\n    n_jobs=-1,\n    **{kk:vv for kk,vv in best_p.items() if kk!=\"k_feats\"}\n).fit(X_tr_final, y_tr_bal_enc)\n\ny_pred_enc = final_lgbm.predict(X_te_final)\ny_pred = label_enc.inverse_transform(y_pred_enc)\n\nacc = accuracy_score(y_te, y_pred)\nf1m = f1_score(y_te, y_pred, average=\"macro\")\n\nprint(\"ðŸ“Š TEST (MBO + LightGBM)\")\nprint(\"Accuracy =\", acc)\nprint(\"Macro-F1 =\", f1m)\nprint(\"\\nSÄ±nÄ±f bazlÄ± rapor:\")\nprint(classification_report(y_te, y_pred, digits=4))\n","metadata":{"_uuid":"e616557a-f15b-454b-a0bd-f332f1cc85ca","_cell_guid":"f84fb341-1f97-46bb-9b11-7ed8bad4e5f2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-18T08:48:00.376514Z","iopub.execute_input":"2025-11-18T08:48:00.376747Z","iopub.status.idle":"2025-11-18T08:48:11.242647Z","shell.execute_reply.started":"2025-11-18T08:48:00.376730Z","shell.execute_reply":"2025-11-18T08:48:11.241732Z"}},"outputs":[{"name":"stdout","text":"ðŸ“Š TEST (MBO + LightGBM)\nAccuracy = 0.5245426320786185\nMacro-F1 = 0.45739061682359705\n\nSÄ±nÄ±f bazlÄ± rapor:\n              precision    recall  f1-score   support\n\n        LDAP     0.3865    0.6401    0.4820      2831\n       MSSQL     0.8831    0.7515    0.8120      8083\n     NetBIOS     0.3199    0.5366    0.4009      2225\n         Syn     0.0450    0.4454    0.0817       907\n         UDP     0.8000    0.7665    0.7829     12462\n      UDPLag     0.5115    0.1129    0.1849     12465\n\n    accuracy                         0.5245     38973\n   macro avg     0.4910    0.5422    0.4574     38973\nweighted avg     0.6499    0.5245    0.5377     38973\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# ADIM 8: FAST MBO + XGBoost (aynÄ± MI, aynÄ± balanced veri)\n\nprint(\"\\nâš¡ FAST MBO + XGBoost baÅŸlÄ±yor...\\n\")\n\nrng = np.random.RandomState(RANDOM_STATE)\ncv_fast = StratifiedKFold(n_splits=2, shuffle=True, random_state=RANDOM_STATE)\n\nbounds_xgb = {\n    \"learning_rate\": (0.01, 0.3),\n    \"max_depth\": (3, 12),\n    \"min_child_weight\": (1, 8),\n    \"subsample\": (0.6, 1.0),\n    \"colsample_bytree\": (0.6, 1.0),\n    \"gamma\": (0, 3),\n    \"reg_lambda\": (0.3, 2),\n    \"n_estimators\": (200, 400),\n    \"k_feats\": (15, 40)\n}\nint_keys_xgb = [\"max_depth\",\"min_child_weight\",\"n_estimators\",\"k_feats\"]\n\ndef clamp_xgb(p):\n    out = {}\n    for k,(lo,hi) in bounds_xgb.items():\n        v = max(lo, min(hi, p[k]))\n        if k in int_keys_xgb:\n            v = int(round(v))\n        out[k] = v\n    return out\n\ndef sample_xgb():\n    return clamp_xgb({k: rng.uniform(lo,hi) for k,(lo,hi) in bounds_xgb.items()})\n\ndef fitness_xgb(p):\n    p = clamp_xgb(p)\n    k = p[\"k_feats\"]\n    cols = mi_series.head(k).index\n    X = X_tr_bal[cols].values\n    y = y_tr_bal_enc\n\n    accs, f1s = [], []\n    for tr_idx, va_idx in cv_fast.split(X, y):\n        Xtr, Xva = X[tr_idx], X[va_idx]\n        ytr, yva = y[tr_idx], y[va_idx]\n\n        model = XGBClassifier(\n            random_state=RANDOM_STATE,\n            n_jobs=1,\n            tree_method=\"approx\",\n            eval_metric=\"mlogloss\",\n            objective=\"multi:softmax\",\n            num_class=len(np.unique(y)),\n            **{kk:vv for kk,vv in p.items() if kk!=\"k_feats\"}\n        )\n        model.fit(Xtr, ytr)\n        pred = model.predict(Xva)\n        accs.append(accuracy_score(yva, pred))\n        f1s.append(f1_score(yva, pred, average=\"macro\"))\n\n    acc = float(np.mean(accs))\n    f1m = float(np.mean(f1s))\n    score = 0.5*acc + 0.5*f1m\n    return score, acc, f1m, cols\n\npop_size = 8\ngens     = 5\npopulation = [sample_xgb() for _ in range(pop_size)]\nbest_s2, best_p2, best_cols2 = -1, None, None\nbest_acc2 = best_f12 = 0\n\n# baÅŸlangÄ±Ã§\nfor p in population:\n    s,a,f,c = fitness_xgb(p)\n    if s > best_s2:\n        best_s2, best_p2, best_cols2 = s,p,c\n        best_acc2, best_f12 = a,f\n\nprint(f\"BaÅŸlangÄ±Ã§ | Score={best_s2:.4f} (Acc={best_acc2:.4f}, F1={best_f12:.4f}), k={len(best_cols2)}\")\n\nfor g in range(gens):\n    new_pop = []\n    for p in population:\n        q = p.copy()\n        for k,(lo,hi) in bounds_xgb.items():\n            if rng.rand() < 0.15:\n                q[k] += rng.uniform(-0.1,0.1)*(hi-lo)\n        new_pop.append(clamp_xgb(q))\n\n    for i in range(pop_size):\n        for k,(lo,hi) in bounds_xgb.items():\n            delta = best_p2[k] - new_pop[i][k]\n            new_pop[i][k] += 0.3*delta + rng.uniform(-0.05,0.05)\n        new_pop[i] = clamp_xgb(new_pop[i])\n\n    for p in new_pop:\n        s,a,f,c = fitness_xgb(p)\n        if s > best_s2:\n            best_s2, best_p2, best_cols2 = s,p,c\n            best_acc2, best_f12 = a,f\n\n    population = new_pop\n    print(f\"Nesil {g+1}/{gens} | Score={best_s2:.4f} (Acc={best_acc2:.4f}, F1={best_f12:.4f}), k={len(best_cols2)}\")\n\nprint(\"\\nâœ… FAST MBO + XGBoost bitti.\")\nprint(\"En iyi XGBoost parametreleri:\")\nfor k,v in best_p2.items():\n    print(f\" - {k}: {v}\")\n","metadata":{"_uuid":"0722475e-0574-4f71-8df3-21703a20a14a","_cell_guid":"3a4b1e77-5e69-4121-9001-ce593cb1cabc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-18T08:48:11.243650Z","iopub.execute_input":"2025-11-18T08:48:11.243994Z","iopub.status.idle":"2025-11-18T09:10:00.882428Z","shell.execute_reply.started":"2025-11-18T08:48:11.243975Z","shell.execute_reply":"2025-11-18T09:10:00.881466Z"}},"outputs":[{"name":"stdout","text":"\nâš¡ FAST MBO + XGBoost baÅŸlÄ±yor...\n\nBaÅŸlangÄ±Ã§ | Score=0.6425 (Acc=0.6510, F1=0.6340), k=37\nNesil 1/5 | Score=0.6456 (Acc=0.6508, F1=0.6403), k=37\nNesil 2/5 | Score=0.6465 (Acc=0.6516, F1=0.6413), k=37\nNesil 3/5 | Score=0.6472 (Acc=0.6549, F1=0.6394), k=37\nNesil 4/5 | Score=0.6551 (Acc=0.6609, F1=0.6492), k=38\nNesil 5/5 | Score=0.6551 (Acc=0.6609, F1=0.6492), k=38\n\nâœ… FAST MBO + XGBoost bitti.\nEn iyi XGBoost parametreleri:\n - learning_rate: 0.2074357360564174\n - max_depth: 9\n - min_child_weight: 3\n - subsample: 0.6595140100584167\n - colsample_bytree: 0.644422993929691\n - gamma: 1.7282582942036426\n - reg_lambda: 1.2995772327613526\n - n_estimators: 298\n - k_feats: 38\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# ADIM 9: Test setinde FAST MBO + XGBoost performansÄ±\n\nX_tr_final2 = X_tr_bal[best_cols2].values\nX_te_final2 = X_te[best_cols2].values\n\nfinal_xgb = XGBClassifier(\n    random_state=RANDOM_STATE,\n    n_jobs=-1,\n    tree_method=\"approx\",\n    eval_metric=\"mlogloss\",\n    objective=\"multi:softmax\",\n    num_class=len(np.unique(y_tr_bal_enc)),\n    **{kk:vv for kk,vv in best_p2.items() if kk!=\"k_feats\"}\n).fit(X_tr_final2, y_tr_bal_enc)\n\ny_pred_enc2 = final_xgb.predict(X_te_final2)\ny_pred2 = label_enc.inverse_transform(y_pred_enc2)\n\nacc2 = accuracy_score(y_te, y_pred2)\nf1m2 = f1_score(y_te, y_pred2, average=\"macro\")\n\nprint(\"ðŸ“Š TEST (FAST MBO + XGBoost)\")\nprint(\"Accuracy =\", acc2)\nprint(\"Macro-F1 =\", f1m2)\nprint(\"\\nSÄ±nÄ±f bazlÄ± rapor:\")\nprint(classification_report(y_te, y_pred2, digits=4))\n","metadata":{"_uuid":"c4ea0f49-432e-427e-8368-450225738553","_cell_guid":"3d8a0b1d-6799-4760-ac35-fb9e6e51fa04","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-18T09:10:00.883358Z","iopub.execute_input":"2025-11-18T09:10:00.883625Z","iopub.status.idle":"2025-11-18T09:10:15.595126Z","shell.execute_reply.started":"2025-11-18T09:10:00.883607Z","shell.execute_reply":"2025-11-18T09:10:15.594125Z"}},"outputs":[{"name":"stdout","text":"ðŸ“Š TEST (FAST MBO + XGBoost)\nAccuracy = 0.5243886793421086\nMacro-F1 = 0.45354286789269826\n\nSÄ±nÄ±f bazlÄ± rapor:\n              precision    recall  f1-score   support\n\n        LDAP     0.3875    0.6623    0.4889      2831\n       MSSQL     0.8865    0.7537    0.8147      8083\n     NetBIOS     0.2939    0.5303    0.3782      2225\n         Syn     0.0370    0.3616    0.0672       907\n         UDP     0.8138    0.7705    0.7916     12462\n      UDPLag     0.5257    0.1091    0.1807     12465\n\n    accuracy                         0.5244     38973\n   macro avg     0.4907    0.5313    0.4535     38973\nweighted avg     0.6580    0.5244    0.5385     38973\n\n","output_type":"stream"}],"execution_count":18}]}